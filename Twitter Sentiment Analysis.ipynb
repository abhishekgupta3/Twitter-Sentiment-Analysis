{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "completed-wagner",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "contrary-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "\n",
    "# NLTK libraries\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Sci-kit libraries\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-cemetery",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "governmental-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Dataset/training.1600000.processed.noemoticon.csv\")\n",
    "data = data.sample(n=20000) # using random sample of the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adolescent-horizontal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56962</th>\n",
       "      <td>0</td>\n",
       "      <td>1685546194</td>\n",
       "      <td>Sun May 03 00:53:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LanieSays</td>\n",
       "      <td>pretty exhausted but can't fall asleep.   I ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555070</th>\n",
       "      <td>0</td>\n",
       "      <td>2203987444</td>\n",
       "      <td>Wed Jun 17 01:02:01 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>poojalapasia</td>\n",
       "      <td>is finding Opera Unite very tempting but compl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194881</th>\n",
       "      <td>4</td>\n",
       "      <td>1984531724</td>\n",
       "      <td>Sun May 31 15:17:28 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>PinkHeart27</td>\n",
       "      <td>on my way to see you Babe!!!!! LYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568120</th>\n",
       "      <td>0</td>\n",
       "      <td>2207421605</td>\n",
       "      <td>Wed Jun 17 07:55:02 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>iLenexLeNi</td>\n",
       "      <td>@Shishu95: HELP ME!!!!!! AGHHH. no freaking in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854755</th>\n",
       "      <td>4</td>\n",
       "      <td>1573442612</td>\n",
       "      <td>Tue Apr 21 01:11:28 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>alaverdyan</td>\n",
       "      <td>wondering why in the world did Suzanne and Jam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  \\\n",
       "56962    0  1685546194  Sun May 03 00:53:07 PDT 2009  NO_QUERY   \n",
       "555070   0  2203987444  Wed Jun 17 01:02:01 PDT 2009  NO_QUERY   \n",
       "1194881  4  1984531724  Sun May 31 15:17:28 PDT 2009  NO_QUERY   \n",
       "568120   0  2207421605  Wed Jun 17 07:55:02 PDT 2009  NO_QUERY   \n",
       "854755   4  1573442612  Tue Apr 21 01:11:28 PDT 2009  NO_QUERY   \n",
       "\n",
       "        _TheSpecialOne_  \\\n",
       "56962         LanieSays   \n",
       "555070     poojalapasia   \n",
       "1194881     PinkHeart27   \n",
       "568120       iLenexLeNi   \n",
       "854755       alaverdyan   \n",
       "\n",
       "        @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "56962    pretty exhausted but can't fall asleep.   I ha...                                                                   \n",
       "555070   is finding Opera Unite very tempting but compl...                                                                   \n",
       "1194881                on my way to see you Babe!!!!! LYM                                                                    \n",
       "568120   @Shishu95: HELP ME!!!!!! AGHHH. no freaking in...                                                                   \n",
       "854755   wondering why in the world did Suzanne and Jam...                                                                   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "satisfactory-junction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "contained-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['target','ids','Date','flag','user','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "opposite-fever",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 56962 to 1333505\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   target  20000 non-null  int64 \n",
      " 1   ids     20000 non-null  int64 \n",
      " 2   Date    20000 non-null  object\n",
      " 3   flag    20000 non-null  object\n",
      " 4   user    20000 non-null  object\n",
      " 5   text    20000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fuzzy-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnessary features\n",
    "\n",
    "data.drop(['ids','Date','flag','user'],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "capital-light",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10028\n",
       "4     9972\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-chicago",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "instrumental-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bottom-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "spectacular-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending punctuations in stopwords\n",
    "\n",
    "punctuations = [char for char in punctuations]\n",
    "for char in punctuations:\n",
    "    stop.append(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "recognized-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+') # only aplhabets \n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "democratic-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanWords(text):\n",
    "    \n",
    "    # lower the text message\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove links\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',text)\n",
    "    \n",
    "     # remove usernames\n",
    "    text = re.sub('@[^\\s]+','',text) \n",
    "    \n",
    "     # remove additional whitespaces\n",
    "    text = re.sub('[\\s]+', ' ', text)\n",
    "    \n",
    "    # Regex tokenizer\n",
    "    text = tokenizer.tokenize(text)\n",
    "    \n",
    "    # Stopwords removal and Stemming using porter stemmer\n",
    "    meaningful = [ps.stem(word) for word in text if not word in stop]\n",
    "        \n",
    "\n",
    "    return ' '.join(meaningful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "complicated-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = data['text'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "statewide-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-62d339a4664d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['text'][i] = cleanWords(data['text'][i])\n"
     ]
    }
   ],
   "source": [
    "# Cleaning all texts in dataFrame\n",
    "\n",
    "for i in key:\n",
    "    data['text'][i] = cleanWords(data['text'][i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "compliant-spank",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56962</th>\n",
       "      <td>0</td>\n",
       "      <td>pretti exhaust fall asleep dine enemi wolf she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555070</th>\n",
       "      <td>0</td>\n",
       "      <td>find opera unit tempt complic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194881</th>\n",
       "      <td>4</td>\n",
       "      <td>way see babe lym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568120</th>\n",
       "      <td>0</td>\n",
       "      <td>help aghhh freak internet whole 10 day mann im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854755</th>\n",
       "      <td>4</td>\n",
       "      <td>wonder world suzann jame robertson write quot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176703</th>\n",
       "      <td>4</td>\n",
       "      <td>standbi tre blog link blast sunday read pleasur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135256</th>\n",
       "      <td>0</td>\n",
       "      <td>ugh work comput serious broken get program use...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text\n",
       "56962         0  pretti exhaust fall asleep dine enemi wolf she...\n",
       "555070        0                      find opera unit tempt complic\n",
       "1194881       4                                   way see babe lym\n",
       "568120        0  help aghhh freak internet whole 10 day mann im...\n",
       "854755        4  wonder world suzann jame robertson write quot ...\n",
       "1176703       4    standbi tre blog link blast sunday read pleasur\n",
       "135256        0  ugh work comput serious broken get program use..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-chicago",
   "metadata": {},
   "source": [
    "##  Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "magnetic-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "minimal-angola",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , Y_train, Y_test = train_test_split(data, data['target'],test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "identified-wholesale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 2), (4000, 2))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "executive-peter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         target                                               text\n",
       " 556468        0                                also repli bad hear\n",
       " 329592        0  made dinner everyon went ikea eat iron made sw...\n",
       " 1365925       4                           yeah down hour bit c goe\n",
       " 221031        0                               sad see church later\n",
       " 896574        4  sicker yesterday scream voic think go doctor s...,\n",
       " 556468     0\n",
       " 329592     0\n",
       " 1365925    4\n",
       " 221031     0\n",
       " Name: target, dtype: int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(5), Y_train.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-disclosure",
   "metadata": {},
   "source": [
    "## Creating vocab and data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "unnecessary-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "precise-injury",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdidf = TfidfVectorizer(analyzer='word', max_features=2000, max_df = 0.8, ngram_range=(1,1))\n",
    "X_train_vectorized = tdidf.fit_transform(X_train.text)\n",
    "X_test_vectorized = tdidf.transform(X_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "related-highland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 2000), (4000, 2000))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized.shape, X_test_vectorized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-campus",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-giant",
   "metadata": {},
   "source": [
    "### <font color= 'red'>Logistic Regression </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "peaceful-interface",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.72      0.73      1996\n",
      "           4       0.73      0.73      0.73      2004\n",
      "\n",
      "    accuracy                           0.73      4000\n",
      "   macro avg       0.73      0.73      0.73      4000\n",
      "weighted avg       0.73      0.73      0.73      4000\n",
      "\n",
      "Accuracy  0.7275\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C = 2.1, solver='liblinear', multi_class='auto')\n",
    "logreg.fit(X_train_vectorized, Y_train)\n",
    "Y_pred_lr = logreg.predict(X_test_vectorized)\n",
    "\n",
    "cf_lr = classification_report(Y_pred_lr,Y_test)\n",
    "score_lr = accuracy_score(Y_pred_lr,Y_test)\n",
    "\n",
    "print(cf_lr)\n",
    "print(\"Accuracy \" ,score_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-limit",
   "metadata": {},
   "source": [
    "### <font color= 'red'>SVC </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "chief-conservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72      1980\n",
      "           4       0.72      0.72      0.72      2020\n",
      "\n",
      "    accuracy                           0.72      4000\n",
      "   macro avg       0.72      0.72      0.72      4000\n",
      "weighted avg       0.72      0.72      0.72      4000\n",
      "\n",
      "Accuracy  0.7215\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train_vectorized, Y_train)\n",
    "Y_pred_svc = svc.predict(X_test_vectorized)\n",
    "\n",
    "cf_svc = classification_report(Y_pred_svc,Y_test)\n",
    "score_svc = accuracy_score(Y_pred_svc,Y_test)\n",
    "print(cf_svc)\n",
    "print(\"Accuracy \" , score_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-island",
   "metadata": {},
   "source": [
    "### <font color= 'red'>Random Forest Classifier </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "virgin-things",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70      1944\n",
      "           4       0.72      0.71      0.71      2056\n",
      "\n",
      "    accuracy                           0.71      4000\n",
      "   macro avg       0.71      0.71      0.71      4000\n",
      "weighted avg       0.71      0.71      0.71      4000\n",
      "\n",
      "Accuracy  0.707\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_vectorized, Y_train)\n",
    "Y_pred_rf = rf.predict(X_test_vectorized)\n",
    "\n",
    "cf_rf = classification_report(Y_pred_rf,Y_test)\n",
    "score_rf = accuracy_score(Y_pred_rf,Y_test)\n",
    "\n",
    "print(cf_rf)\n",
    "print(\"Accuracy \" ,score_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-recycling",
   "metadata": {},
   "source": [
    "### <font color= 'red'>Decision Tree Classifier </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "embedded-hospital",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      2005\n",
      "           4       0.66      0.67      0.67      1995\n",
      "\n",
      "    accuracy                           0.67      4000\n",
      "   macro avg       0.67      0.67      0.67      4000\n",
      "weighted avg       0.67      0.67      0.67      4000\n",
      "\n",
      "Accuracy  0.66575\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train_vectorized, Y_train)\n",
    "Y_pred_dt = dt.predict(X_test_vectorized)\n",
    "\n",
    "cf_dt = classification_report(Y_pred_dt,Y_test)\n",
    "score_dt = accuracy_score(Y_pred_dt,Y_test)\n",
    "print(cf_dt)\n",
    "print(\"Accuracy \" ,score_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-province",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-burst",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
